{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8768a7a-0ddd-4a54-a5dc-83a7aed97a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics, NDArrays, Scalar, Parameters, ndarrays_to_parameters, parameters_to_ndarrays\n",
    "import yaml\n",
    "import os\n",
    "import tempfile\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from flwr.server.strategy import FedAvg, FedProx, FedAvgM, FedOpt\n",
    "from scripts.diffusion_models.diffusion_model import *\n",
    "from scripts.pde_solvers.pde_solver_5clients import FWIForward \n",
    "from torch.optim import Adam\n",
    "from scripts.data_utils.data_trans import v_normalize, v_denormalize, s_normalize_none, s_normalize, s_denormalize\n",
    "import torch.multiprocessing as mp\n",
    "from configs.config_utils import AppConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37785b4-ae56-4687-b333-c42963616d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load configuration & setup diffusion model ###\n",
    "\n",
    "def load_config(path):\n",
    "    with open(path) as f:\n",
    "        raw_config = yaml.safe_load(f)\n",
    "    return AppConfig(**raw_config)\n",
    "\n",
    "config = load_config('configs/config_5clients.yml')\n",
    "\n",
    "mp.set_start_method('spawn', force=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## setup forward solver ##\n",
    "ctx = {\n",
    "    'n_grid': config.forward.n_grid, 'nt': config.forward.nt, \n",
    "    'dx': config.forward.dx, 'nbc': config.forward.nbc, \n",
    "    'dt': config.forward.dt, 'f': config.forward.f,\n",
    "    'sz': config.forward.sz, 'gz': config.forward.gz,\n",
    "    'ng': config.forward.ng, 'ns': config.forward.ns\n",
    "}\n",
    "\n",
    "fwi_forward = FWIForward(ctx, device, normalize=True, \n",
    "                         v_denorm_func=v_denormalize, \n",
    "                         s_norm_func=s_normalize_none)\n",
    "\n",
    "## setup diffusion model ##\n",
    "diffusion_args = {\n",
    "    'dim': config.diffusion.dim, 'dim_mults': config.diffusion.dim_mults, \n",
    "    'flash_attn': config.diffusion.flash_attn, 'channels': config.diffusion.channels,\n",
    "    'image_size': config.diffusion.image_size, 'timesteps': config.diffusion.timesteps, \n",
    "    'sampling_timesteps': config.diffusion.sampling_timesteps, \n",
    "    'objective': config.diffusion.objective\n",
    "}\n",
    "\n",
    "\n",
    "unet_model = Unet(\n",
    "    dim=diffusion_args.get('dim'),\n",
    "    dim_mults=diffusion_args.get('dim_mults'),\n",
    "    flash_attn=diffusion_args.get('flash_attn'),\n",
    "    channels=diffusion_args.get('channels')\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    unet_model,\n",
    "    image_size=diffusion_args.get('image_size'),\n",
    "    timesteps=diffusion_args.get('timesteps'),\n",
    "    sampling_timesteps=diffusion_args.get('sampling_timesteps'),\n",
    "    objective=diffusion_args.get('objective')\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c94cad9-4e95-4c77-b1a1-b105c5b2e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load & prepare data ###\n",
    "velocity_data_path = config.path.velocity_data_path\n",
    "seismic_data_path = config.path.seismic_data_path\n",
    "model_path = config.path.model_path\n",
    "output_path = config.path.output_path\n",
    "\n",
    "checkpoint = torch.load(model_path, weights_only=True)\n",
    "state_dict = checkpoint.get('model', checkpoint)\n",
    "diffusion.load_state_dict(state_dict)\n",
    "diffusion.eval()\n",
    "unwrapped_diffusion_model = diffusion\n",
    "unwrapped_diffusion_model.eval()\n",
    "diffusion_state_dict = unwrapped_diffusion_model.state_dict()\n",
    "\n",
    "seismic_data = torch.tensor(np.load(seismic_data_path + \"/CF_test.npy\")[0:1,:]).float().to(device)\n",
    "vm_data = torch.tensor(np.load(velocity_data_path + \"/CF_test.npy\")[0:1,:]).float()\n",
    "\n",
    "initial_model = data_trans.prepare_initial_model(vm_data, initial_type='smoothed', \n",
    "                                                 sigma=config.forward.initial_sigma)\n",
    "initial_model = F.pad(initial_model, (1, 1, 1, 1), \"constant\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8485ea2a-0452-4747-800e-d1c0999dc58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn_factory(partitions: List[torch.Tensor]):\n",
    "    \"\"\"\n",
    "    This is a factory function that returns a new `client_fn` for simulation.\n",
    "    The returned `client_fn` will have the `partitions` in its closure.\n",
    "    \"\"\"\n",
    "\n",
    "    def client_fn(context: Context) -> flwr.client.Client:\n",
    "        \"\"\"This is the actual client function that will be executed by the actor.\"\"\"\n",
    "        \n",
    "        # ==================== THE FINAL FIX ====================\n",
    "        # Ignore the broken context.node_id.\n",
    "        # Get the correct ID from the node_config dictionary and convert to int.\n",
    "        client_id = int(context.node_config[\"partition-id\"])\n",
    "        # =======================================================\n",
    "        \n",
    "        # This line will now work correctly with the proper client_id.\n",
    "        local_data_for_client = partitions[client_id]\n",
    "\n",
    "        # Instantiate your FwiClient as before\n",
    "        fwi_client_instance = FwiClient(\n",
    "            cid=str(client_id),\n",
    "            device=device,\n",
    "            fwi_forward=fwi_forward,\n",
    "            data_trans=data_trans,\n",
    "            ssim_loss=ssim_loss,\n",
    "            local_data=local_data_for_client,\n",
    "            num_total_clients=config.experiment.num_clients,\n",
    "            diffusion_state_dict=diffusion_state_dict,\n",
    "            diffusion_model_structure_args=diffusion_args\n",
    "        )\n",
    "        \n",
    "        return fwi_client_instance.to_client()\n",
    "\n",
    "    # Return the configured client_fn\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d132a873-013a-4719-b0f6-c6a532085fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
      "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
      "\n",
      "\t\t$ flwr new  # Create a new Flower app from a template\n",
      "\n",
      "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
      "\n",
      "\tUsing `start_simulation()` is deprecated.\n",
      "\n",
      "            This is a deprecated feature. It will be removed\n",
      "            entirely in future versions of Flower.\n",
      "        \n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=750, no round_timeout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for Client 0: torch.Size([1, 1, 1000, 70])\n",
      "Data shape for Client 1: torch.Size([1, 1, 1000, 70])\n",
      "Data shape for Client 2: torch.Size([1, 1, 1000, 70])\n",
      "Data shape for Client 3: torch.Size([1, 1, 1000, 70])\n",
      "Data shape for Client 4: torch.Size([1, 1, 1000, 70])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 06:28:24,086\tWARNING utils.py:580 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2025-07-30 06:28:24,276\tINFO worker.py:1771 -- Started a local Ray instance.\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'accelerator_type:G': 1.0, 'node:__internal_head__': 1.0, 'node:172.17.0.10': 1.0, 'CPU': 18.0, 'memory': 30926819328.0, 'object_store_memory': 15463409664.0, 'GPU': 1.0}\n",
      "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.5}\n",
      "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.20425251126289368, {'seismic_loss': 0.19651004672050476, 'diffusion_loss': 0.010323275811970234, 'mae': 0.18572062253952026, 'rmse': 0.23281880952618708, 'ssim': 0.5602846741676331}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 3: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 1: FWI with Diffusion regularization, using local data partition.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 4: FWI with Diffusion regularization, using local data partition.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 5 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.1273268312215805, {'seismic_loss': 0.1271466463804245, 'diffusion_loss': 0.00024025073798839003, 'mae': 0.18396824598312378, 'rmse': 0.23422338827221767, 'ssim': 0.5472772717475891}, 20.78380996361375)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 5 clients (out of 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 1: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\n",
      "\u001b[36m(ClientAppActor pid=284965)\u001b[0m Client 3: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284965)\u001b[0m Using Total_Variation method\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 2: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\n",
      "\u001b[36m(ClientAppActor pid=284965)\u001b[0m Client 4: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284965)\u001b[0m Using Total_Variation method\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/server/server.py:353\u001b[0m, in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    349\u001b[0m     submitted_fs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    350\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(fit_client, client_proxy, ins, timeout, group_id)\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m client_proxy, ins \u001b[38;5;129;01min\u001b[39;00m client_instructions\n\u001b[1;32m    352\u001b[0m     }\n\u001b[0;32m--> 353\u001b[0m     finished_fs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Gather results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m client_resources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_gpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.5\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_cpus\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[1;32m     71\u001b[0m ray_init_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_dashboard\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_temp_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mray_temp\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m---> 73\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Use the function from the factory\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfed_rounds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mray_init_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray_init_args\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m final_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m final_parameters_store:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/simulation/legacy_app.py:361\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    366\u001b[0m     log(ERROR, ex)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/server/server.py:492\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_fl\u001b[39m(\n\u001b[1;32m    488\u001b[0m     server: Server,\n\u001b[1;32m    489\u001b[0m     config: ServerConfig,\n\u001b[1;32m    490\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m History:\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m     hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    497\u001b[0m     log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[SUMMARY]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/server/server.py:115\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    113\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ROUND \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_round)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Train model and replace previous global model\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m res_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_fit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     parameters_prime, fit_metrics, _ \u001b[38;5;241m=\u001b[39m res_fit  \u001b[38;5;66;03m# fit_metrics_aggregated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/server/server.py:234\u001b[0m, in \u001b[0;36mServer.fit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    226\u001b[0m log(\n\u001b[1;32m    227\u001b[0m     INFO,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigure_fit: strategy sampled \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m clients (out of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mlen\u001b[39m(client_instructions),\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_manager\u001b[38;5;241m.\u001b[39mnum_available(),\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Collect `fit` results from all clients participating in this round\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m results, failures \u001b[38;5;241m=\u001b[39m \u001b[43mfit_clients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_instructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m log(\n\u001b[1;32m    241\u001b[0m     INFO,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate_fit: received \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m results and \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failures\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mlen\u001b[39m(results),\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28mlen\u001b[39m(failures),\n\u001b[1;32m    245\u001b[0m )\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Aggregate training results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/flwr/server/server.py:348\u001b[0m, in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_clients\u001b[39m(\n\u001b[1;32m    342\u001b[0m     client_instructions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[ClientProxy, FitIns]],\n\u001b[1;32m    343\u001b[0m     max_workers: Optional[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    344\u001b[0m     timeout: Optional[\u001b[38;5;28mfloat\u001b[39m],\n\u001b[1;32m    345\u001b[0m     group_id: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    346\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FitResultsAndFailures:\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Refine parameters concurrently on all selected clients.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_proxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient_proxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mins\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclient_instructions\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinished_fs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubmitted_fs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handled in the respective communication stack\u001b[39;49;00m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/concurrent/futures/thread.py:238\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 238\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:1147\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:1167\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1168\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Client 0: FWI with Diffusion regularization, using local data partition.\n",
      "\u001b[36m(ClientAppActor pid=284964)\u001b[0m Using Total_Variation method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1753828186 on cpu 103 ***\n",
      "PC: @     0x7ffa227cd01e  (unknown)  epoll_wait\n",
      "    @     0x7ffa226e9520  (unknown)  (unknown)\n",
      "[2025-07-30 06:29:46,924 E 281150 281150] logging.cc:440: *** SIGTERM received at time=1753828186 on cpu 103 ***\n",
      "[2025-07-30 06:29:46,924 E 281150 281150] logging.cc:440: PC: @     0x7ffa227cd01e  (unknown)  epoll_wait\n",
      "[2025-07-30 06:29:46,924 E 281150 281150] logging.cc:440:     @     0x7ffa226e9520  (unknown)  (unknown)\n"
     ]
    }
   ],
   "source": [
    "from scripts.flwr.flwr_client import FwiClient\n",
    "from scripts.flwr.flwr_evaluation import get_evaluate_fn\n",
    "from scripts.flwr.flwr_utils import *\n",
    "import scripts.data_utils.pytorch_ssim \n",
    "from flwr.common import Context\n",
    "import flwr\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "if diffusion_state_dict is not None and diffusion_args is not None:\n",
    "    server_diffusion_model = diffusion\n",
    "    \n",
    "ssim_loss = pytorch_ssim.SSIM(window_size=11)  \n",
    "final_parameters_store = {} \n",
    "num_clients = config.experiment.num_clients\n",
    "regularization = config.experiment.regularization\n",
    "fed_rounds = config.federated.num_rounds\n",
    "local_epochs = config.federated.local_epochs\n",
    "local_lr = config.federated.local_lr\n",
    "\n",
    "evaluate_fn = get_evaluate_fn(\n",
    "    model_shape=initial_model.shape,\n",
    "    seismic_data=seismic_data,\n",
    "    mu_true=vm_data,\n",
    "    fwi_forward=fwi_forward,\n",
    "    data_trans=data_trans,\n",
    "    ssim_loss=ssim_loss,\n",
    "    device=device,\n",
    "    diffusion_model=server_diffusion_model,\n",
    "    total_rounds=config.federated.num_rounds,\n",
    "    final_params_store=final_parameters_store\n",
    ")\n",
    "\n",
    "def fit_config_fn(server_round: int):\n",
    "    return {\n",
    "        \"server_round\": server_round, \"local_epochs\": local_epochs,\n",
    "        \"local_lr\": local_lr, \"total_rounds\": fed_rounds, \"regularization\": regularization\n",
    "    }\n",
    "client_data_partitions = []\n",
    "\n",
    "for i in range(5):\n",
    "    client_data_partitions.append(seismic_data[:,i:i+1,:,:])\n",
    "    \n",
    "for i, data in enumerate(client_data_partitions):\n",
    "    print(f\"Data shape for Client {i}: {data.shape}\")\n",
    "\n",
    "\n",
    "client_fn_instance = client_fn_factory(client_data_partitions)\n",
    "\n",
    "strategy_classes = {\n",
    "    \"FedAvg\": FedAvg,\n",
    "    \"FedProx\": FedProx, \n",
    "    \"FedAvgM\": FedAvgM,\n",
    "    \"FedOpt\": FedOpt\n",
    "}\n",
    "\n",
    "# Get the actual class\n",
    "strategy_class = strategy_classes[config.experiment.strategy]\n",
    "strategy_params = {\"server_momentum\": config.experiment.server_momentum}\n",
    "\n",
    "strategy = strategy_class(\n",
    "    fraction_fit=1.0, \n",
    "    min_fit_clients=config.experiment.num_clients,\n",
    "    min_available_clients=config.experiment.num_clients,\n",
    "    evaluate_fn=evaluate_fn, \n",
    "    fraction_evaluate=0.0, \n",
    "    on_fit_config_fn=fit_config_fn,\n",
    "    initial_parameters=ndarrays_to_parameters(tensor_to_ndarrays(initial_model.to(device))),\n",
    "    **strategy_params\n",
    ")\n",
    "client_resources = {\"num_cpus\": 1, \"num_gpus\": 0.5} if device.type == 'cuda' else {\"num_cpus\": 2}\n",
    "ray_init_args = {\"include_dashboard\": False, \"_temp_dir\": os.path.join(os.getcwd(), \"ray_temp\")}\n",
    "\n",
    "history = fl.simulation.start_simulation(\n",
    "    client_fn=client_fn_instance, # Use the function from the factory\n",
    "    num_clients=num_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=fed_rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    "    ray_init_args=ray_init_args\n",
    ")\n",
    "\n",
    "final_model = None\n",
    "if \"final_model\" in final_parameters_store:\n",
    "    saved_ndarrays = final_parameters_store[\"final_model\"]\n",
    "    final_model = ndarrays_to_tensor(saved_ndarrays, device)\n",
    "    print(\"Successfully loaded final model.\")\n",
    "else:\n",
    "    print(\"Warning: final_model not found in store. Using initial model.\")\n",
    "    final_model = test_initial_model\n",
    "\n",
    "if final_model is None:\n",
    "    print(f\"Warning: Could not retrieve final model for {strategy_name}, using initial model\")\n",
    "    final_model = test_initial_model\n",
    "with torch.no_grad():\n",
    "    model_input = final_model[:, :, 1:-1, 1:-1]\n",
    "    predicted_seismic = fwi_forward(model_input)\n",
    "    seismic_loss = l1_loss_fn(seismic_data.float(), predicted_seismic.float())\n",
    "    vm_sample = model_input.detach().to('cpu')\n",
    "    vm_true_norm = v_normalize(vm_data)\n",
    "    if vm_true_norm.dim() == 2:\n",
    "        vm_true_norm = vm_true_norm.unsqueeze(0).unsqueeze(0)\n",
    "    vm_true_norm = vm_true_norm.to('cpu')\n",
    "\n",
    "    if vm_sample.shape != vm_true_norm.shape:\n",
    "        h_diff = vm_sample.shape[2] - vm_true_norm.shape[2]\n",
    "        w_diff = vm_sample.shape[3] - vm_true_norm.shape[3]\n",
    "        if h_diff >= 0 and w_diff >= 0 and h_diff % 2 == 0 and w_diff % 2 == 0:\n",
    "            h_start, w_start = h_diff // 2, w_diff // 2\n",
    "            h_end, w_end = h_start + vm_true_norm.shape[2], w_start + vm_true_norm.shape[3]\n",
    "            vm_sample = vm_sample[:, :, h_start:h_end, w_start:w_end]\n",
    "\n",
    "    mae = l1_loss_fn(vm_sample, vm_true_norm).item()\n",
    "    mse = l2_loss_fn(vm_sample, vm_true_norm).item()\n",
    "    rmse = np.sqrt(mse)\n",
    "    ssim_val = ssim_loss((vm_sample + 1) / 2, (vm_true_norm + 1) / 2).item()\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "strategy_results = {\n",
    "    'strategy': strategy_name,\n",
    "    'final_model': final_model.cpu().detach().numpy(),\n",
    "    'metrics_history': history.metrics_centralized,\n",
    "    'losses_history': history.losses_centralized,\n",
    "    'final_metrics': {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'ssim': ssim_val,\n",
    "        'seismic_loss': seismic_loss.item()\n",
    "    },\n",
    "\n",
    "    'config': {\n",
    "        'fed_rounds': fed_rounds,\n",
    "        'local_epochs': local_epochs,\n",
    "        'local_lr': local_lr,\n",
    "        'num_clients': num_clients,\n",
    "        'strategy_params': strategy_params\n",
    "    }\n",
    "}\n",
    "\n",
    "filename = f\"results/{strategy_name}_results_{timestamp}.pkl\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(strategy_results, f)\n",
    "print(f\"{strategy_name} results saved to {filename}\")\n",
    "\n",
    "with open(f\"results/{strategy_name}_summary_{timestamp}.txt\", 'w') as f:\n",
    "    f.write(f\"{strategy_name} Results\\n\")\n",
    "    f.write(f\"Run at: {timestamp}\\n\\n\")\n",
    "    f.write(f\"Final MAE: {mae:.6f}\\n\")\n",
    "    f.write(f\"Final RMSE: {rmse:.6f}\\n\")\n",
    "    f.write(f\"Final SSIM: {ssim_val:.6f}\\n\")\n",
    "    f.write(f\"Final Seismic Loss: {seismic_loss.item():.6f}\\n\\n\")\n",
    "    f.write(f\"Configuration:\\n\")\n",
    "    f.write(f\"  Fed Rounds: {fed_rounds}\\n\")\n",
    "    f.write(f\"  Local Epochs: {local_epochs}\\n\")\n",
    "    f.write(f\"  Local Learning Rate: {local_lr}\\n\")\n",
    "    f.write(f\"  Number of Clients: {num_clients}\\n\")\n",
    "    f.write(f\"  Strategy Parameters: {strategy_params}\\n\")\n",
    "\n",
    "all_results[strategy_name] = strategy_results\n",
    "plot_path = f\"results/{strategy_name}_plots\"\n",
    "os.makedirs(plot_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95c1b0-6f12-4323-b0c6-b2c0cd541dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
